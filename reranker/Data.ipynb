{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import optparse, sys, os\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class opts:\n",
    "    reference = os.path.join(\"data\", \"train.en\")\n",
    "    nbest = os.path.join(\"data\", \"train.nbest\")\n",
    "\n",
    "translation_candidate = namedtuple(\"candidate\", \"sentence, inverse_scores, features\")\n",
    "ref = [line.strip().split() for line in open(opts.reference)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 0 lines\n",
      "loaded 2000 lines\n",
      "loaded 4000 lines\n",
      "loaded 6000 lines\n",
      "loaded 8000 lines\n",
      "loaded 10000 lines\n"
     ]
    }
   ],
   "source": [
    "nbests = []\n",
    "for n, line in enumerate(open(opts.nbest)):\n",
    "    (i, sentence, features) = line.strip().split(\"|||\")\n",
    "    (i, sentence) = (int(i), sentence.strip())\n",
    "    features = np.array([float(it) for it in features.split()])\n",
    "    if len(ref) <= i:\n",
    "        break\n",
    "\n",
    "    while len(nbests) <= i:\n",
    "        nbests.append([])\n",
    "\n",
    "    scores = tuple(bleu.bleu_stats(sentence.split(), ref[i]))\n",
    "    inverse_scores = tuple([-x for x in scores])\n",
    "    smoothed_score = bleu.smoothed_bleu(inverse_scores)\n",
    "\n",
    "    nbests[i].append((translation_candidate(sentence, inverse_scores, features), smoothed_score))\n",
    "\n",
    "    if n % 2000 == 0:\n",
    "        print('loaded %d lines' % n)\n",
    "\n",
    "    # small size for testing, delete it when release\n",
    "    if n > 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau = 5000\n",
    "alpha = 0.1\n",
    "xi = 100\n",
    "eta = 0.1\n",
    "epochs = 5\n",
    "theta = np.array([1.0 / len(features) for _ in range(len(features))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 1\n",
      "epoch 2\n",
      "epoch 3\n",
      "epoch 4\n"
     ]
    }
   ],
   "source": [
    "mistakes = 0\n",
    "discount = 0.7\n",
    "for i in range(epochs):\n",
    "    for nbest in nbests:\n",
    "\n",
    "        def get_sample():\n",
    "            sample = []\n",
    "            for i in range(tau):\n",
    "                # s1, s2 = random.sample(nbest, 2)\n",
    "                s1 = random.choice(nbest)\n",
    "                s2 = random.choice(nbest)\n",
    "                if math.fabs(s1[1] - s2[1]) > alpha:\n",
    "                    if s1[1] > s2[1]:\n",
    "                        sample.append((s1, s2))\n",
    "                    else:\n",
    "                        sample.append((s2, s2))\n",
    "                else:\n",
    "                    continue\n",
    "            return sample\n",
    "\n",
    "        samples = sorted(get_sample(), key=lambda s: s[0][1] - s[1][1], reverse=True)\n",
    "        samples = samples[:xi]\n",
    "        \n",
    "        # grad = np.zeros_like(theta)\n",
    "        pre_grad = np.zeros_like(theta)\n",
    "        \n",
    "        for s in samples:\n",
    "            s1 = s[0][0]\n",
    "            s2 = s[1][0]\n",
    "            if np.dot(theta, s1.features) <= np.dot(theta, s2.features):\n",
    "                mistakes += 1\n",
    "                \n",
    "                grad = s1.features - s2.features\n",
    "                pre_grad = pre_grad * 0.1 + grad * eta\n",
    "                # print pre_grad\n",
    "                theta += grad * eta\n",
    "                \n",
    "        del(samples)\n",
    "    print \"epoch\", \n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2846, array([ 0.19636667,  0.16666667, -0.03333333,  0.16666667,  0.36666667,\n",
       "         0.24506667]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98241355471\n",
      "0.0965299639668\n",
      "-1.82244868587\n",
      "0.0965299639668\n",
      "-9.01896975028\n",
      "-3.38351481355\n"
     ]
    }
   ],
   "source": [
    "for i in theta:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
