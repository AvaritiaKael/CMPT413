import time
import perc
import sys
import optparse
import os
from include.feature_vector import FeatureVector
# from collections import defaultdict


def retrieve_feature(output, feat_list):
    # This function returns feature vector generated by certain output
    feat_vec = FeatureVector()
    index = 0

    for i in range(1, len(output)-1):
        (index, feats) = perc.feats_for_word(index, feat_list)

        if len(feats) == 0:
            raise ValueError("Returned empty feature")

        for feat in feats:
            feat_vec[feat, output[i]] += 1

    return feat_vec


def avg_perc_train(train_data, tagset, iterations=1):
    feat_vec = FeatureVector()
    feat_vec_sum = FeatureVector()
    last_change_dict = FeatureVector()
    total_sentence_count = 0
    default_tag = tagset[0]

    for iteration in range(iterations):
        # Number of Sentences
        sentence_total = len(train_data)
        sentence_count = 0

        for (labeled_list, feat_list) in train_data:
            # For averaged perceptron, we need to know exactly how many
            # sentences we have used during training
            total_sentence_count += 1

            # Print out information
            sentence_count += 1
            print "iteration", iteration, "sentence", sentence_count, "of", sentence_total

            # Retrieve Gold Output
            gold_output = []
            gold_output.append('B_-1')
            for i in labeled_list:
                (w, t, label) = i.split()
                gold_output.append(label)
            gold_output.append('B_+1')

            # Retrieve Local Output
            local_output = perc.perc_test(feat_vec,
                                          labeled_list,
                                          feat_list,
                                          tagset,
                                          default_tag)
            local_output.insert(0, 'B_-1')
            local_output.append('B_+1')

            print gold_output
            print local_output

            # Extract features from both outputs
            local_vec = retrieve_feature(local_output, feat_list)
            gold_vec  = retrieve_feature(gold_output, feat_list)

            # Calculate delta
            delta_vec = gold_vec - local_vec

            # This is the key to averaged perceptron, it sums up all the
            # feat_vec we have used, and returns the averaged value by
            # dividing that sum with the total_sentence_count(total number
            # of sentences used during training, including duplicates
            # during multiple iterations)

            #    feat_vec += delta_vec
            #    feat_vec_sum += feat_vec

            # The following is the optimisation for averaged perceptron
            # which does exactly the same thing as the code in the above two
            # lines. Instead of updating the feat_vec_sum everytime we train
            # a new sentence, we do lazy update.
            if sentence_count != sentence_total:
                # Not the last sentence of current iteration
                if not gold_vec == local_vec:
                    for key in delta_vec:
                        # Only update the changed values, and store when they
                        # was last updated
                        feat_vec_sum[key] += feat_vec[key] * (total_sentence_count - last_change_dict[key])
                        last_change_dict[key] = total_sentence_count

                    feat_vec += delta_vec
                    # Because feat_vec is updated here by adding delta_vec, we
                    # do exactly the same thing to feat_vec_sum, because it is
                    # in its nature, a sum of feat_vecs
                    feat_vec_sum += delta_vec
            else:
                # Is the last sentence of current iteration, we need to apply
                # all pending updates to feat_vec_sum
                for key in last_change_dict.keys() + feat_vec.keys():
                    # Just to make sure we have indeed updated every key.
                    feat_vec_sum[key] += feat_vec[key] * (total_sentence_count - last_change_dict[key])
                    last_change_dict[key] = total_sentence_count

                if not gold_vec == local_vec:
                    # Last but not least, don't forget the current delta_vec
                    feat_vec += delta_vec
                    feat_vec_sum += delta_vec

        # Dump every iteration
        tmp = feat_vec_sum / total_sentence_count
        tmp.dump("models/jetic_avg_Iter_" + str(iteration) + ".model")

    # Finalisation, divide feat_vec_sum with total_sentence_count
    feat_vec = feat_vec_sum / total_sentence_count

    return feat_vec.export()

if __name__ == '__main__':
    optparser = optparse.OptionParser()
    optparser.add_option("-t", "--tagsetfile", dest="tagsetfile", default=os.path.join("data", "tagset.txt"), help="tagset that contains all the labels produced in the output, i.e. the y in \phi(x,y)")
    optparser.add_option("-i", "--trainfile", dest="trainfile", default=os.path.join("data", "train.txt.gz"), help="input data, i.e. the x in \phi(x,y)")
    optparser.add_option("-f", "--featfile", dest="featfile", default=os.path.join("data", "train.feats.gz"), help="precomputed features for the input data, i.e. the values of \phi(x,_) without y")
    optparser.add_option("-e", "--numepochs", dest="numepochs", default=int(10), help="number of epochs of training; in each epoch we iterate over over all the training examples")
    optparser.add_option("-m", "--modelfile", dest="modelfile", default=os.path.join("data", "default.model"), help="weights for all features stored on disk")
    (opts, _) = optparser.parse_args()

    # each element in the feat_vec dictionary is:
    # key=feature_id value=weight
    feat_vec = {}
    tagset = []
    train_data = []

    tagset = perc.read_tagset(opts.tagsetfile)
    print >>sys.stderr, "reading data ..."
    train_data = perc.read_labeled_data(opts.trainfile, opts.featfile)
    print >>sys.stderr, "done."
    start_time = time.time()
    feat_vec = avg_perc_train(train_data, tagset, int(opts.numepochs))
    end_time = time.time()
    print "Total training Time(seconds): %f" % (end_time - start_time,)
    perc.perc_write_to_file(feat_vec, opts.modelfile)
