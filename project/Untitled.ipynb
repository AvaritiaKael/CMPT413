{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import optparse, sys, os, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_file = 'nlp-data/small/train.cn'\n",
    "target_file = 'nlp-data/small/train.en'\n",
    "phrase_file = 'nlp-data/small/phrase-table/moses/phrase-table'\n",
    "show_limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lines(fp, k_line=5, verbose=False, preprocess=lambda x:x):\n",
    "    res = []\n",
    "    for idx, line in enumerate(open(fp)):\n",
    "        if k_line > 0 and idx >= k_line:\n",
    "            break\n",
    "        \n",
    "        res.append(preprocess(line))\n",
    "        if verbose:\n",
    "            print line\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_sentence = lambda x: tuple(x.strip().split())\n",
    "fr = get_lines(source_file, preprocess=split_sentence)\n",
    "en = get_lines(target_file, preprocess=split_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase_table = get_lines(phrase_file, k_line=-1, verbose=False, preprocess=lambda x:x.strip().split('|||'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('temporary_tm.txt', 'w+') as fp:\n",
    "    for each in phrase_table:\n",
    "        fp.write('%s|||%s||| %s\\n' %(each[0], each[1], math.log(float(each[2].strip().split()[0].strip()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import decoder.models as models\n",
    "from decoder.jetic_decoder import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading translation model from temporary_tm.txt...\n",
      "Reading language model from lm...\n"
     ]
    }
   ],
   "source": [
    "tm = models.TM('temporary_tm.txt', 1)\n",
    "lm = models.LM('lm')\n",
    "for word in set(sum(fr,())):\n",
    "    if (word,) not in tm:\n",
    "        tm[(word,)] = [models.phrase(word, 0.0)]\n",
    "decoder = Decoder(tm, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding sentence 1 of 5\n",
      "processing the 1th phrase of 13, stack size: 1\n",
      "processing the 2th phrase of 13, stack size: 13\n",
      "processing the 3th phrase of 13, stack size: 156\n",
      "processing the 4th phrase of 13, stack size: 1716\n",
      "processing the 5th phrase of 13, stack size: 5000\n",
      "processing the 6th phrase of 13, stack size: 5000\n",
      "processing the 7th phrase of 13, stack size: 5000\n",
      "processing the 8th phrase of 13, stack size: 5000\n",
      "processing the 9th phrase of 13, stack size: 5000\n",
      "processing the 10th phrase of 13, stack size: 5000\n",
      "processing the 11th phrase of 13, stack size: 5000\n",
      "processing the 12th phrase of 13, stack size: 5000\n",
      "processing the 13th phrase of 13, stack size: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英 女皇 伊 利 沙 伯 二 世 陛下 登基 第三 十四 年\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding sentence 2 of 5\n",
      "processing the 1th phrase of 15, stack size: 1\n",
      "processing the 2th phrase of 15, stack size: 15\n",
      "processing the 3th phrase of 15, stack size: 210\n",
      "processing the 4th phrase of 15, stack size: 2730\n",
      "processing the 5th phrase of 15, stack size: 5000\n",
      "processing the 6th phrase of 15, stack size: 5000\n",
      "processing the 7th phrase of 15, stack size: 5000\n",
      "processing the 8th phrase of 15, stack size: 5000\n",
      "processing the 9th phrase of 15, stack size: 5000\n",
      "processing the 10th phrase of 15, stack size: 5000\n",
      "processing the 11th phrase of 15, stack size: 5000\n",
      "processing the 12th phrase of 15, stack size: 5000\n",
      "processing the 13th phrase of 15, stack size: 5000\n",
      "processing the 14th phrase of 15, stack size: 5000\n",
      "processing the 15th phrase of 15, stack size: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "於 一 九 八五年 十月 三十日 开始 的 会期 内 立法 局 辩论 正式 纪录\n",
      "立法 局 会议 厅\n",
      "一 九 八五年 十月 三十日 星期三\n",
      "下午 四时 四 十分 开始 会议\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding sentence 3 of 5\n",
      "processing the 1th phrase of 4, stack size: 1\n",
      "processing the 2th phrase of 4, stack size: 4\n",
      "processing the 3th phrase of 4, stack size: 12\n",
      "processing the 4th phrase of 4, stack size: 24\n",
      "Decoding sentence 4 of 5\n",
      "processing the 1th phrase of 6, stack size: 1\n",
      "processing the 2th phrase of 6, stack size: 6\n",
      "processing the 3th phrase of 6, stack size: 30\n",
      "processing the 4th phrase of 6, stack size: 120\n",
      "processing the 5th phrase of 6, stack size: 360\n",
      "processing the 6th phrase of 6, stack size: 720\n",
      "Decoding sentence 5 of 5\n",
      "processing the 1th phrase of 6, stack size: 1\n",
      "processing the 2th phrase of 6, stack size: 6\n",
      "processing the 3th phrase of 6, stack size: 30\n",
      "processing the 4th phrase of 6, stack size: 120\n",
      "processing the 5th phrase of 6, stack size: 360\n",
      "processing the 6th phrase of 6, stack size: 720\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for f in fr[:5]:\n",
    "    count += 1\n",
    "    sys.stderr.write(\"Decoding sentence \" + str(count) + \" of \" + str(len(fr)) + \"\\n\")\n",
    "    decoder.decode(f,\n",
    "                   maxPhraseLen=20,\n",
    "                   maxStackSize=5000,\n",
    "                   maxTranslation=20,\n",
    "                   saveToList=False,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.5572201\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
